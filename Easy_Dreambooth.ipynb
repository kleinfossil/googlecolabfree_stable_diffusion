{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO9BoGE2hQl76YN51fuOoqw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kleinfossil/googlecolabfree_stable_diffusion/blob/easy_sd/Easy_Dreambooth.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Welcome\n",
        "This is a super simplified version to train your AI based on your pictures.\n",
        "\n",
        "If you just want to create pictures go to my [easy stable diffusion page](https://colab.research.google.com/drive/1spMMW7J7Y-PNNIoJuhyxqHpIQFxcy5Ft?usp=sharing).\n",
        "\n",
        "More Details on my [detailed AI page](https://colab.research.google.com/drive/1YnAbmwpBuMOKP57RooXwQw01Z9r3Epg_?usp=sharing)."
      ],
      "metadata": {
        "id": "z1H_qcZCNHvS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How to use?\n",
        "This will train an AI model on pictures you will upload. \n",
        "\n",
        "This trained AI model will understand your trigger word.\n",
        "</br> Means if you train it on pictures of your cat and name the trigger \"**mycat**\" you can use it in the AI prompt. E.g. \"**A picture of mycat**\". \n",
        "\n",
        "The class prompt is a general category of your trigger word. In this case the class prompt could be \"**a picture of a cat**\" or just \"**cat**\"\n",
        "\n",
        "<font color=green>**INFO:**</font> \n",
        "1.   When you press the arrow, you will be asked to upload pictures. These pictures will be **deleted** after you close the runtime.\n",
        "2.   Only upload **5-20 pictures**\n",
        "3.   Training an AI takes time. It will take about: **40 Minutes**. Depending on the amout of pictures you upload (more take more time)\n",
        "4.   Everything runs in a virtual machine on google colab. If you do not click \"Save_to_Google_Drive your model will just exists until you close your browser or disconnect this session.\n",
        "5.   Savining on Google Drive will take **2GB** per model.\n",
        "6.   Google offers **free** computing power but it is **limited** to a 3-4 hours a day. So if you do not use it close the browser tab or click on: Runtime/Disconnect and delete runtime."
      ],
      "metadata": {
        "id": "JfQ-_-3dpK-x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trainer Your Model"
      ],
      "metadata": {
        "id": "tnnU3qYaCilc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This code was made so that a model can be trained with one click. \n",
        "# Thats the reason why I put all the code in one Cell. \n",
        "# If you want to split it you can do it at the \"---\" points\n",
        "\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# --- Setup Parameters ---\n",
        "print(\"Setup Parameters...\")\n",
        "\n",
        "import re\n",
        "# Input Parameters\n",
        "MODEL_NAME = \"runwayml/stable-diffusion-v1-5\" \n",
        "\n",
        "#@markdown Write a short unique word.\n",
        "Your_Trigger_Word = \"kasfaceb\" #@param {type:\"string\"}\n",
        "#@markdown Write a word or short text which discribes your pictures.\n",
        "Class_Prompt = \"head shot of a man\" #@param {type:\"string\"}\n",
        "#@markdown Check if you want to save your model. Requires 2GB\n",
        "Save_to_Google_Drive = True #@param {type:\"boolean\"}\n",
        "\n",
        "# This will use a regex to make the prompt a valid foldername\n",
        "your_prompt_as_folder_name = output = re.sub(r'\\W+', '', Your_Trigger_Word)\n",
        "class_prompt_as_folder_name = output = re.sub(r'\\W+', '', Class_Prompt)\n",
        "\n",
        "#While training the AI will need a directory. \n",
        "Instance_Data_Directory = f\"/content/data/{your_prompt_as_folder_name}\"\n",
        "Class_Data_Directory = f\"/content/data/{class_prompt_as_folder_name}\"\n",
        "OUTPUT_DIR = f\"/content/model/{your_prompt_as_folder_name}\"\n",
        "\n",
        "\n",
        "# You can also add multiple concepts here. Try tweaking `--max_train_steps` accordingly.\n",
        "\n",
        "concepts_list = [\n",
        "    {\n",
        "        \"instance_prompt\":      Your_Trigger_Word,\n",
        "        \"class_prompt\":         Class_Prompt,\n",
        "        \"instance_data_dir\":    Instance_Data_Directory,\n",
        "        \"class_data_dir\":       Class_Data_Directory\n",
        "    },\n",
        "#     {\n",
        "#         \"instance_prompt\":      \"photo of ukj person\",\n",
        "#         \"class_prompt\":         \"photo of a person\",\n",
        "#         \"instance_data_dir\":    \"/content/data/ukj\",\n",
        "#         \"class_data_dir\":       \"/content/data/person\"\n",
        "#     }\n",
        "]\n",
        "\n",
        "# This just creates a json of the concepts_list. Maybe one da I want to train more then one concept.\n",
        "import json\n",
        "import os\n",
        "for c in concepts_list:\n",
        "    os.makedirs(c[\"instance_data_dir\"], exist_ok=True)\n",
        "\n",
        "with open(\"concepts_list.json\", \"w\") as f:\n",
        "    json.dump(concepts_list, f, indent=4)\n",
        "\n",
        "\n",
        "# --- Connect to Google Drive if required ---\n",
        "print(\"Connecting to Google Drive...\")\n",
        "if Save_to_Google_Drive:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "# --- Upload Images ---\n",
        "print(\"Upload images...\")\n",
        "\n",
        "import os\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "for c in concepts_list:\n",
        "    print(f\"Uploading instance images for `{c['instance_prompt']}`\")\n",
        "    uploaded = files.upload()\n",
        "    for filename in uploaded.keys():\n",
        "        dst_path = os.path.join(c['instance_data_dir'], filename)\n",
        "        shutil.move(filename, dst_path)\n",
        "clear_output()\n",
        "\n",
        "\n",
        "# --- Install Requirements ---\n",
        "print(\"Install requirements...\")\n",
        "\n",
        "# Install Dreambooth requirements\n",
        "!wget -q https://github.com/ShivamShrirao/diffusers/raw/main/examples/dreambooth/train_dreambooth.py\n",
        "clear_output()\n",
        "!wget -q https://github.com/ShivamShrirao/diffusers/raw/main/scripts/convert_diffusers_to_original_stable_diffusion.py\n",
        "clear_output()\n",
        "%pip install git+https://github.com/ShivamShrirao/diffusers\n",
        "clear_output()\n",
        "%pip install -U --pre triton\n",
        "clear_output()\n",
        "%pip install accelerate==0.12.0 transformers ftfy bitsandbytes gradio natsort\n",
        "clear_output()\n",
        "\n",
        "# Install xformers\n",
        "%pip install -q https://github.com/brian6091/xformers-wheels/releases/download/0.0.15.dev0%2B4c06c79/xformers-0.0.15.dev0+4c06c79.d20221205-cp38-cp38-linux_x86_64.whl\n",
        "clear_output()\n",
        "# These were compiled on Tesla T4.\n",
        "\n",
        "# If precompiled wheels don't work, install it with the following command. It will take around 40 minutes to compile.\n",
        "# %pip install git+https://github.com/facebookresearch/xformers@4c06c79#egg=xformers\n",
        "\n",
        "\n",
        "# --- Train the Model ---\n",
        "print(\"Train Model...\")\n",
        "\n",
        "# Count the number of images to get a rough idea of the training steps required.\n",
        "# A rule of thumb is 100 steps per image.\n",
        "import os\n",
        "\n",
        "# folder path\n",
        "dir_path = Instance_Data_Directory\n",
        "number_of_files = 0\n",
        "# Iterate directory\n",
        "for path in os.listdir(dir_path):\n",
        "    # check if current path is a file\n",
        "    if os.path.isfile(os.path.join(dir_path, path)):\n",
        "        number_of_files += 1\n",
        "\n",
        "MAX_TRAINING_STEPS = int(number_of_files*100)\n",
        "\n",
        "# Launch the Training\n",
        "\n",
        "!accelerate launch train_dreambooth.py \\\n",
        "  --pretrained_model_name_or_path=$MODEL_NAME \\\n",
        "  --pretrained_vae_name_or_path=\"stabilityai/sd-vae-ft-mse\" \\\n",
        "  --output_dir=$OUTPUT_DIR \\\n",
        "  --revision=\"fp16\" \\\n",
        "  --with_prior_preservation --prior_loss_weight=1.0 \\\n",
        "  --seed=1337 \\\n",
        "  --resolution=512 \\\n",
        "  --train_batch_size=1 \\\n",
        "  --train_text_encoder \\\n",
        "  --mixed_precision=\"fp16\" \\\n",
        "  --use_8bit_adam \\\n",
        "  --gradient_accumulation_steps=1 \\\n",
        "  --learning_rate=1e-6 \\\n",
        "  --lr_scheduler=\"constant\" \\\n",
        "  --lr_warmup_steps=0 \\\n",
        "  --num_class_images=50 \\\n",
        "  --sample_batch_size=4 \\\n",
        "  --max_train_steps=$MAX_TRAINING_STEPS \\\n",
        "  --save_interval=30000 \\\n",
        "  --save_sample_prompt=Instance_Prompt \\\n",
        "  --concepts_list=\"concepts_list.json\"\n",
        "\n",
        "clear_output()\n",
        "\n",
        "# -- Create Packaged Model ---\n",
        "\n",
        "CKPT_PATH = f\"/content/packaged/{your_prompt_as_folder_name}\" + \".ckpt\"\n",
        "GDRIVE_PATH = f\"/content/drive/MyDrive/Dreambooth/models/\"\n",
        "\n",
        "#Run conversion.\n",
        "half_arg = \"\"\n",
        "\n",
        "#Whether to convert to fp16, takes half the space (2GB).\n",
        "WEIGHTS_DIR = \"\"\n",
        "if WEIGHTS_DIR == \"\":\n",
        "    from natsort import natsorted\n",
        "    from glob import glob\n",
        "    import os\n",
        "    WEIGHTS_DIR = natsorted(glob(OUTPUT_DIR + os.sep + \"*\"))[-1]\n",
        "%mkdir /content/packaged\n",
        "\n",
        "fp16 = True\n",
        "if fp16:\n",
        "    half_arg = \"--half\"\n",
        "!python convert_diffusers_to_original_stable_diffusion.py --model_path $WEIGHTS_DIR  --checkpoint_path $CKPT_PATH $half_arg\n",
        "final_model_path = CKPT_PATH\n",
        "clear_output()\n",
        "print(f\"Path to local Model: {final_model_path}\")\n",
        "\n",
        "# -- Copy Model to Google Drive if required ---\n",
        "if Save_to_Google_Drive:\n",
        "  print(\"Copy Model to Google Drive...\")\n",
        "  # copy source to destination\n",
        "  %mkdir -p $GDRIVE_PATH\n",
        "  %cp -av $CKPT_PATH $GDRIVE_PATH\n",
        "  clear_output()\n",
        "  print(f\"You can find your Model on your Google Drive here: {GDRIVE_PATH}\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "MMBMq-3eOXHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Your Model\n",
        "Let's test your model. \n",
        "First time execution will take **3 Minutes**. Afterwards it takes just seconds\n"
      ],
      "metadata": {
        "id": "hYoJu6S7tDAI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output # Will clear lines in the text output\n",
        "import os\n",
        "from torch import autocast\n",
        "\n",
        "# --- Select Model Path ---\n",
        "#@markdown **Model Path**\n",
        "#@markdown\n",
        "#@markdown Put the path to your model here. E.g. /content/drive/MyDrive/Dreambooth/models/kasmediumshot.ckpt\n",
        "#@markdown\n",
        "#@markdown If you just created a model you can **keep this empty**\n",
        "Model_Path = \"\" #@param {type:\"string\"}\n",
        "model_path_was_filled = True\n",
        "\n",
        "# If the training cell was just executed then this data can be used.\n",
        "if Model_Path == \"\":\n",
        "  model_path_was_filled = False \n",
        "else:\n",
        "  if \"/drive/MyDrive/\" in Model_Path:\n",
        "    print(\"Connecting to Google Drive...\")\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive') \n",
        "    clear_output()\n",
        "\n",
        "\n",
        "# --- Run easy stable diffusion code ---\n",
        "\n",
        "# Checks if pipe already exists. \n",
        "# If yes it will ignore the except block\n",
        "# If not it will get an NameError and execute the except block\n",
        "try: pipe\n",
        "except NameError:\n",
        "  \n",
        "  # Install addtional modules\n",
        "  %pip install diffusers\n",
        "  clear_output()\n",
        "  %pip install transformers\n",
        "  clear_output()\n",
        "  %pip install OmegaConf\n",
        "  clear_output()\n",
        "  %pip install accelerate\n",
        "  clear_output()\n",
        "\n",
        "  # conditional import of the just installed modules.\n",
        "  import torch\n",
        "  from diffusers import StableDiffusionPipeline, DDIMScheduler\n",
        "  from omegaconf import OmegaConf  \n",
        "\n",
        "  if model_path_was_filled:\n",
        "    # This Code will unpack the ckpt file. This is only needed if a packed model was provided. \n",
        "    # Not required if the model was justed created \n",
        "    \n",
        "    # This converts the ckpt back to a normal model. \n",
        "    TEMPORARY_MODEL = \"/content/unpacked_model\"   \n",
        "    if os.path.exists(TEMPORARY_MODEL):\n",
        "      print(\"Model Path already exists\")\n",
        "    else:\n",
        "      print(\"Unpack Model...\")\n",
        "      %mkdir $TEMPORARY_MODEL\n",
        "      #Downloads and execute a file which was written to unpack ckpt files for stable diffusion models\n",
        "      print(\"Download Stable Diffusion ckpt converter...\")\n",
        "      !wget -O convert_original_stable_diffusion_to_diffusers.py https://raw.githubusercontent.com/huggingface/diffusers/main/scripts/convert_original_stable_diffusion_to_diffusers.py\n",
        "      clear_output()\n",
        "      print(\"Convert ckpt to model...\")\n",
        "      !python /content/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path $Model_Path --dump_path $TEMPORARY_MODEL\n",
        "      clear_output()\n",
        "    \n",
        "    WEIGHTS_DIR = TEMPORARY_MODEL\n",
        " \n",
        "  # Set a specific Scheduler for the AI\n",
        "  scheduler = DDIMScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", clip_sample=False, set_alpha_to_one=False)\n",
        "  # Create pipe with model\n",
        "  clear_output()\n",
        "  print(\"Preparing Model Pipe...\")\n",
        "  pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    WEIGHTS_DIR, \n",
        "    scheduler=scheduler, \n",
        "    safety_checker=None, \n",
        "    torch_dtype=torch.float16\n",
        "  ).to(\"cuda\")\n",
        "  clear_output()\n",
        "\n",
        "#@markdown **Write a prompt with your trigger word**\n",
        "prompt = \"kasfaceb as an astronaut, cinematic, epic, dramatic light, futuristic, cyberpunk, photo realistic, photography, detailed, landscape shot\" #@param {type:\"string\"}\n",
        "#@markdown **How many Images do you want?** </br> More images take more time (~15seconds per image).\n",
        "images = 10 #@param {type:\"number\"}\n",
        "\n",
        "#Basic input Parameter - Play around with them when you are more advanced\n",
        "negative_prompt = \"\" # Add a negative prompt\n",
        "num_samples = images # Number of images generated\n",
        "guidance_scale = 7.5 # How close should be the images to the text\n",
        "num_inference_steps = 50 # Number of steps till the image is generated (50 is recommended)\n",
        "height = 512 # hight of the output image\n",
        "width = 512 #@ width of the output image\n",
        "\n",
        "# Start generation of images\n",
        "print(\"Create Images...\")\n",
        "with autocast(\"cuda\"):\n",
        "    images = pipe(\n",
        "        prompt,\n",
        "        height=height,\n",
        "        width=width,\n",
        "        negative_prompt=negative_prompt,\n",
        "        num_images_per_prompt=num_samples,\n",
        "        num_inference_steps=num_inference_steps,\n",
        "        guidance_scale=guidance_scale,\n",
        "    ).images\n",
        "\n",
        "# Display the images below each other\n",
        "for img in images:\n",
        "    display(img)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "9QyzFVO_vMQx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}