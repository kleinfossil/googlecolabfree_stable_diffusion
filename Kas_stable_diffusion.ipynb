{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kleinfossil/googlecolabfree_stable_diffusion/blob/main/Kas_stable_diffusion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Welcome\n",
        "**Disclaimer**\n",
        "\n",
        "This code was tested last time -never- . The AI World changes really fast and it is possible that this code does not run anymore.  \n",
        "\n",
        "**How to start**\n",
        "\n",
        "Depending on your needs you will need to run several code snippets one by one.\n",
        "To run a code snipped click on the small arrow on the left side of the snipped at every step.\n",
        "\n",
        "Run the <font color='red'>initital Setup</font> first.\n",
        "\n",
        "Afterwards there are two options what you can do with this Notebook: \n",
        "\n",
        "\n",
        "1.   <font color='green'>Generate new Images via an Web User Interface</font>\n",
        "2.   <font color='purple'>Train a new AI model so that it generates images of a specific object or person</font>\n",
        "\n",
        "**Before you start**\n",
        "\n",
        "This codes runs with with Google Colab free. This means that you can use Google resources to generate images or train models. However these **resources are limited**. You will have access to a Graphic Card just for a few hours until you have to wait 24h-48h to get a new one. Therefore check first if you can get a GPU from Google. If no GPU is available you might need to come back another day.\n",
        "\n",
        "When you are done, always **close the runtime** by clicking on \"Runtime/Disconnect and Delete Runtime\" or by closing your browser tab. IMPORTANT: Closing the runtime will delete eveything which was not save on Google Drive.  \n"
      ],
      "metadata": {
        "id": "OmFnmrFZXSUY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "XU7NuMAA2drw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c722e5a-f1f1-4811-ad41-e640066d8dbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla T4, 15109 MiB, 15109 MiB\n"
          ]
        }
      ],
      "source": [
        "#@markdown <font color='red'>**INITAL STEP 1:**</font>\n",
        "#@markdown Check if you can start a GPU. The output should be: Tesla T4, 15109 MiB, 15109 MiB\n",
        "!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## HuggingFace Setup\n",
        "\n",
        "You also need to have a huggingface account. Huggingface is a website which manages the models of this type of AI. All Models come from there\n",
        "\n",
        "If you are already logged in and created your Token just copy it from the [access token page](https://huggingface.co/settings/tokens).\n",
        "If not follow these steps:\n",
        "\n",
        "1.   Sign Up on [HuggingFace.co](https://huggingface.co/ )\n",
        "2.   Then click on your profile on the right upper corner\n",
        "3.   Then click on \"Setting\" \n",
        "4.   Click on the \"Access Tokens\"\n",
        "5.   If not already done create a new Token with READ Access\n",
        "6.   Then copy the generated Token below\n",
        "\n"
      ],
      "metadata": {
        "id": "Aek7f6d5jgCZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown <font color='red'>**INTIAL STEP 2:**</font> Copy Past your huggingface token ðŸ¤—\n",
        "\n",
        "!mkdir -p ~/.huggingface\n",
        "HUGGINGFACE_TOKEN = \"\" #@param {type:\"string\"}\n",
        "!echo -n \"{HUGGINGFACE_TOKEN}\" > ~/.huggingface/token"
      ],
      "metadata": {
        "cellView": "form",
        "id": "z6XuEqclj4ZK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GDrive Connection\n",
        "\n",
        "Every Google Account has also a Google Drive. You access it via: https://drive.google.com/drive/my-drive .\n",
        "\n",
        "Before you go further you should check that you have at least **9GB** of free space on your drive. (If you want to do both, WebUI and Model Training)\n",
        "\n",
        "**Connect to Google Drive**\n",
        "\n",
        "Click on the small arrow to connect to google drive. Than you will be asked to approve the connection. After you have approved it the code will be save on your drive."
      ],
      "metadata": {
        "id": "MiHr46ZdeKnx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown <font color=\"red\">**INITAL STEP 3:**</font> Connect to Google Drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "5s0HfzRqgYyx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "0d22cf73-eab6-4765-ebc6-e85529722c22"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Further Infos\n",
        "\n",
        "More infos for this code can be found here: \n",
        "\n",
        "Original Colab - [Web User Interface](https://colab.research.google.com/github/TheLastBen/fast-stable-diffusion/blob/main/fast_stable_diffusion_AUTOMATIC1111.ipynb) \n",
        "\n",
        "Original Colab - [New Model Creation](https://colab.research.google.com/github/ShivamShrirao/diffusers/blob/main/examples/dreambooth/DreamBooth_Stable_Diffusion.ipynb)\n",
        "\n",
        "Learn how [Diffusion Models](https://jalammar.github.io/illustrated-stable-diffusion/) work.\n",
        "\n",
        "Learn how Stable Diffusion (the AI Model) [actually works](https://pub.towardsai.net/getting-started-with-stable-diffusion-f343639e4931)."
      ],
      "metadata": {
        "id": "gBFCFryuoo0h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Option 1:** Generate Images via WebUI"
      ],
      "metadata": {
        "id": "CkZ4-lokawt1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnTMyW41cC1E"
      },
      "source": [
        "## Install WebUI\n",
        "You will need to make to installation just once. As soon as you have everything downloaded to your Google Drive there is no need to make another installation\n",
        "\n",
        "(This Step will take about 1 Minute when running the first time and will install ~150MB on google Drive)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown <font color='green'>**WebUI STEP 1:**</font> Inital Installation\n",
        "from IPython.utils import capture\n",
        "from IPython.display import clear_output\n",
        "from subprocess import getoutput\n",
        "from google.colab import runtime\n",
        "from IPython.display import display_markdown\n",
        "import time\n",
        "\n",
        "# Installs automatic1111 and stable diffusion\n",
        "with capture.capture_output() as cap:\n",
        "  fgitclone = \"git clone --depth 1\" \n",
        "  %cd /content/gdrive/MyDrive/\n",
        "  %mkdir  sd\n",
        "  %cd sd\n",
        "  !$fgitclone https://github.com/Stability-AI/stablediffusion\n",
        "  !$fgitclone https://github.com/AUTOMATIC1111/stable-diffusion-webui\n",
        "  %cd /content/gdrive/MyDrive/sd/stable-diffusion-webui/\n",
        "  !mkdir -p cache/{huggingface,torch}\n",
        "  %cd /content/\n",
        "  !ln -s /content/gdrive/MyDrive/sd/stable-diffusion-webui/cache/huggingface ../root/.cache/\n",
        "  !ln -s /content/gdrive/MyDrive/sd/stable-diffusion-webui/cache/torch ../root/.cache/\n",
        "  !wget -O /content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/shared.py https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/modules/shared.py\n",
        "\n",
        "Update_repo = True\n",
        "if Update_repo:\n",
        "  with capture.capture_output() as cap:\n",
        "    !rm /content/gdrive/MyDrive/sd/stable-diffusion-webui/webui.sh  \n",
        "    !rm /content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/paths.py\n",
        "    !rm /content/gdrive/MyDrive/sd/stable-diffusion-webui/webui.py \n",
        "    !rm /content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/ui.py\n",
        "    !rm /content/gdrive/MyDrive/sd/stable-diffusion-webui/style.css\n",
        "    %cd /content/gdrive/MyDrive/sd/stable-diffusion-webui/\n",
        "  print('[1;32m')\n",
        "  !git pull\n",
        "  clear_output()\n",
        "  print('\u001b[1;32mInstall Automatic1111 WebUI done !')\n",
        "\n",
        "\n",
        "# Installs all requirements needed for stable diffusion webui\n",
        "import os\n",
        "from re import search\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  \n",
        "  if not os.path.exists('/content/gdrive/MyDrive/sd/stablediffusion/src/k-diffusion/k_diffusion'):\n",
        "    !mkdir /content/gdrive/MyDrive/sd/stablediffusion/src\n",
        "    %cd /content/gdrive/MyDrive/sd/stablediffusion/src\n",
        "    !$fgitclone https://github.com/CompVis/taming-transformers\n",
        "    !$fgitclone https://github.com/openai/CLIP\n",
        "    !$fgitclone https://github.com/salesforce/BLIP\n",
        "\n",
        "    !$fgitclone https://github.com/sczhou/CodeFormer\n",
        "    !$fgitclone https://github.com/crowsonkb/k-diffusion\n",
        "    !mv /content/gdrive/MyDrive/sd/stablediffusion/src/CLIP /content/gdrive/MyDrive/sd/stablediffusion/src/clip\n",
        "    !mv  /content/gdrive/MyDrive/sd/stablediffusion/src/BLIP /content/gdrive/MyDrive/sd/stablediffusion/src/blip    \n",
        "    !mv  /content/gdrive/MyDrive/sd/stablediffusion/src/CodeFormer /content/gdrive/MyDrive/sd/stablediffusion/src/codeformer        \n",
        "    !cp -r /content/gdrive/MyDrive/sd/stablediffusion/src/k-diffusion/k_diffusion /content/gdrive/MyDrive/sd/stable-diffusion-webui/\n",
        "\n",
        "\n",
        "  %cd /content/\n",
        "  for i in range(1,6):\n",
        "      !wget -q \"https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dependencies/Dependencies.{i}\"\n",
        "      !mv \"Dependencies.{i}\" \"Dependencies.7z.00{i}\"\n",
        "  !7z x -y Dependencies.7z.001\n",
        "  time.sleep(2)\n",
        "  !cp -r /content/usr/local/lib/python3.8/dist-packages /usr/local/lib/python3.8/\n",
        "  !rm -r /content/usr\n",
        "  for i in range(1,6):\n",
        "      !rm \"Dependencies.7z.00{i}\"\n",
        "  !pip install -U -q pillow\n",
        "        \n",
        "  %cd /content/gdrive/MyDrive/sd/stable-diffusion-webui/modules\n",
        "  !wget -O paths.py https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/AUTOMATIC1111_files/paths.py\n",
        "\n",
        "  if os.path.exists('/content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/deforum-for-automatic1111-webui/scripts/deforum_helpers/src/infer.py'):\n",
        "    %cd /content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/deforum-for-automatic1111-webui/scripts/deforum_helpers\n",
        "    !wget -O animation.py https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/AUTOMATIC1111_files/deforum/animation.py\n",
        "    !wget -O depth.py https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/AUTOMATIC1111_files/deforum/depth.py    \n",
        "    %cd /content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/deforum-for-automatic1111-webui/scripts/deforum_helpers/src    \n",
        "    !wget -O infer.py https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/AUTOMATIC1111_files/deforum/infer.py\n",
        "\n",
        "  if not os.path.exists('/content/gdrive/MyDrive/sd/stablediffusion/repositories/BoostingMonocularDepth'):\n",
        "    %cd /content/gdrive/MyDrive/sd/stablediffusion\n",
        "    !mkdir repositories\n",
        "    %cd repositories\n",
        "    !git clone https://github.com/isl-org/MiDaS.git midas\n",
        "    !git clone https://github.com/compphoto/BoostingMonocularDepth.git\n",
        "  %cd /content\n",
        "\n",
        "base = '/content/gdrive/MyDrive/sd/stable-diffusion'\n",
        "dirs = [base, f'{base}/src/taming-transformers', f'{base}/src/clip',\n",
        "        f'{base}/src/GFPGAN', f'{base}/src/blip', f'{base}/src/codeformer',\n",
        "        f'{base}/src/realesrgan', f'{base}/src/k-diffusion', f'{base}/src/ldm']\n",
        "for d in dirs:\n",
        "    !rm -rf {d + '/.git'}\n",
        "clear_output()\n",
        "print('\u001b[1;32mInstall Requirements for stable diffusion done!')\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "z1S8qouXhklw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Select or Download Model\n",
        "There are several different version of stable diffusion model available. I recommend to start with 1.5. \n",
        "\n",
        "If you are new, you do not have to change any option, just click on the arrow and run the code block."
      ],
      "metadata": {
        "id": "oie67AZXlAWi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from IPython.display import clear_output\n",
        "import time\n",
        "\n",
        "#@markdown <font color='green'>**WebUI STEP 2:**</font> Model Download/Load\n",
        "#@markdown\n",
        "#@markdown Select the model Version of stable diffusion\n",
        "Model_Version = \"1.5\" #@param [ \"1.5\", \"V2.1-512px\", \"V2.1-768px\"]\n",
        "Redownload_the_original_model = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Or if you have created your own model, add the path to this model here.\n",
        "Path_to_CKPT = \"\" #@param {type:\"string\"}\n",
        "#@markdown Insert the full path of your trained model (eg: /content/gdrive/MyDrive/model.ckpt).\n",
        "\n",
        "# G Drive Link if available\n",
        "Link_CKPT = \"\" \n",
        "\n",
        "Custom_Model_Version=\"1.5\" # [ \"1.5\", \"V2.1-512px\", \"V2.1-768px\"]\n",
        "\n",
        "Path_to_HuggingFace= \"\" # {type:\"string\"}\n",
        "\n",
        "token = HUGGINGFACE_TOKEN\n",
        "\n",
        "RunwayML_Inpainting_Model = False\n",
        "\n",
        "if Redownload_the_original_model:\n",
        "  if os.path.exists('/content/mainmodel.ckpt'):\n",
        "    !rm /content/mainmodel.ckpt\n",
        "  %cd /content/gdrive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion  \n",
        "  !wget -q -O model.ckpt https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/precompiled/README.md\n",
        "  !mv /content/gdrive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion/model.ckpt /content/gdrive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion/trashfile.f  \n",
        "  time.sleep(2)\n",
        "  !rm /content/gdrive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion/trashfile.f\n",
        "  time.sleep(2)\n",
        "  clear_output()\n",
        "\n",
        "\n",
        "\n",
        "def newmdl(token):\n",
        "\n",
        "    if not os.path.exists('/content/gdrive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion/model.ckpt'):\n",
        "      if token==\"\":\n",
        "        token=input(\"Insert your huggingface token :\")\n",
        "      %cd /content/\n",
        "      clear_output()\n",
        "      !git init\n",
        "      !git lfs install --system --skip-repo\n",
        "      !$fgitclone --branch fp16 \"https://USER:{token}@huggingface.co/runwayml/stable-diffusion-v1-5\"\n",
        "      if os.path.exists('/content/stable-diffusion-v1-5'):\n",
        "        !$fgitclone \"https://USER:{token}@huggingface.co/stabilityai/sd-vae-ft-mse\"\n",
        "        !rm -r /content/stable-diffusion-v1-5/vae\n",
        "        !mv /content/sd-vae-ft-mse /content/stable-diffusion-v1-5/vae        \n",
        "        !wget -O convertosd.py https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/convertosd.py\n",
        "        !sed -i '201s@.*@    model_path = \"/content/stable-diffusion-v1-5\"@' /content/convertosd.py\n",
        "        !sed -i '202s@.*@    checkpoint_path= \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion/model.ckpt\"@' /content/convertosd.py\n",
        "        clear_output()       \n",
        "        !python /content/convertosd.py \n",
        "        if os.path.exists('/content/gdrive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion/model.ckpt'):\n",
        "          model='/content/gdrive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion/model.ckpt'\n",
        "          clear_output()\n",
        "          print('\u001b[1;32mModel 1.5 downloaded')\n",
        "        else:\n",
        "          print('\u001b[1;31mSomething went wrong, try again')\n",
        "      else:\n",
        "        print('\u001b[1;31mMake sure you accept the terms at https://huggingface.co/runwayml/stable-diffusion-v1-5')\n",
        "\n",
        "    else:\n",
        "      model='/content/gdrive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion/model.ckpt'\n",
        "      # clear_output()\n",
        "      print('\u001b[1;32mModel already exists, check the box \"Redownload_the_original_model\" to redownload/download the V1.5')\n",
        "\n",
        "    if os.path.exists('/content/.git'):\n",
        "      !rm -r /content/.git\n",
        "\n",
        "    if os.path.exists('/content/stable-diffusion-v1-5'):\n",
        "      !rm -r /content/stable-diffusion-v1-5      \n",
        "\n",
        "\n",
        "def V2(token):\n",
        "\n",
        "    if not os.path.exists('/content/gdrive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion/model.ckpt'):\n",
        "      %cd /content/\n",
        "      clear_output()\n",
        "      !mkdir \"/content/stable-diffusion-V2\"\n",
        "      %cd \"/content/stable-diffusion-V2\"\n",
        "      !git init\n",
        "      !git lfs install --system --skip-repo\n",
        "      if Model_Version == \"V2.1-768px\":\n",
        "        !git remote add -f origin  \"https://USER:{token}@huggingface.co/stabilityai/stable-diffusion-2-1\"\n",
        "      elif Model_Version == \"V2.1-512px\":\n",
        "        !git remote add -f origin  \"https://USER:{token}@huggingface.co/stabilityai/stable-diffusion-2-1-base\" \n",
        "      !git config core.sparsecheckout true\n",
        "      !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nvae\\nmodel_index.json\" > .git/info/sparse-checkout\n",
        "      !git pull origin main\n",
        "      %cd /content\n",
        "      !wget -O convertosdv2.py https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/convertosdv2.py\n",
        "      clear_output()\n",
        "      !python /content/convertosdv2.py --fp16 /content/stable-diffusion-V2 /content/gdrive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion/model.ckpt\n",
        "      if os.path.exists('/content/gdrive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion/model.ckpt'):\n",
        "        model='/content/gdrive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion/model.ckpt'\n",
        "        # clear_output()\n",
        "        print('\u001b[1;32mModel 2.1 downloaded')\n",
        "      else:\n",
        "        print('\u001b[1;31mSomething went wrong, try again')\n",
        "\n",
        "    else:\n",
        "      model='/content/gdrive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion/model.ckpt'\n",
        "      # clear_output()\n",
        "      print('\u001b[1;32mModel already exists, check the box \"Redownload_the_original_model\" to redownload/download the V2.')\n",
        "\n",
        "    if os.path.exists('/content/.git'):\n",
        "      !rm -r /content/.git\n",
        "      !rm -r /content/convertosdv2.py\n",
        "    if os.path.exists('/content/stable-diffusion-V2'):\n",
        "      !rm -r /content/stable-diffusion-V2\n",
        "\n",
        "def inpmdl(token):\n",
        "\n",
        "    if not os.path.exists('/content/gdrive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion/sd-v1-5-inpainting.ckpt'):\n",
        "      if token==\"\":\n",
        "        token=input(\"Insert your huggingface token :\")\n",
        "      %cd /content/\n",
        "      clear_output()\n",
        "      !git init\n",
        "      !git lfs install --system --skip-repo\n",
        "      !$fgitclone --branch fp16 \"https://USER:{token}@huggingface.co/runwayml/stable-diffusion-inpainting\"\n",
        "      if os.path.exists('/content/stable-diffusion-inpainting'):\n",
        "        !$fgitclone \"https://USER:{token}@huggingface.co/stabilityai/sd-vae-ft-mse\"\n",
        "        !rm -r /content/stable-diffusion-inpainting/vae\n",
        "        !mv /content/sd-vae-ft-mse /content/stable-diffusion-inpainting/vae        \n",
        "        !wget -O convertosd.py https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/convertosd.py\n",
        "        !sed -i '201s@.*@    model_path = \"/content/stable-diffusion-inpainting\"@' /content/convertosd.py\n",
        "        !sed -i '202s@.*@    checkpoint_path= \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion/sd-v1-5-inpainting.ckpt\"@' /content/convertosd.py\n",
        "        clear_output()       \n",
        "        !python /content/convertosd.py \n",
        "        if os.path.exists('/content/gdrive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion/sd-v1-5-inpainting.ckpt'):\n",
        "          clear_output()\n",
        "          print('\u001b[1;32mInpaining Version 1.5 downloaded')\n",
        "        else:\n",
        "          print('\u001b[1;31mSomething went wrong, try again')\n",
        "      else:\n",
        "        print('\u001b[1;31mMake sure you have accepted the terms at https://huggingface.co/runwayml/stable-diffusion-inpainting')\n",
        "\n",
        "    else:\n",
        "      clear_output()\n",
        "      print('\u001b[1;32mModel already exists.')\n",
        "\n",
        "    if os.path.exists('/content/.git'):\n",
        "      !rm -r /content/.git\n",
        "\n",
        "    if os.path.exists('/content/stable-diffusion-inpainting'):\n",
        "      !rm -r /content/stable-diffusion-inpainting   \n",
        "\n",
        "\n",
        "if (Path_to_CKPT !=''):\n",
        "  if os.path.exists(str(Path_to_CKPT)):\n",
        "    print('\u001b[1;32mUsing the trained model.')\n",
        "  else:\n",
        "      while not os.path.exists(str(Path_to_CKPT)):\n",
        "        print('\u001b[1;31mWrong path, use the colab file explorer to copy the path : ')\n",
        "        Path_to_CKPT=input()\n",
        "      if os.path.exists(str(Path_to_CKPT)):\n",
        "        print('\u001b[1;32mUsing the trained model.')\n",
        "\n",
        "  model=Path_to_CKPT\n",
        "\n",
        "elif Link_CKPT != \"\":\n",
        "  if os.path.exists('/content/mainmodel.ckpt'):\n",
        "    !rm /content/mainmodel.ckpt\n",
        "  %cd /content/gdrive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion\n",
        "  !wget -q -O model.ckpt https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/precompiled/attention.py\n",
        "  !mv /content/gdrive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion/model.ckpt /content/gdrive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion/trashfile.f  \n",
        "  time.sleep(2)\n",
        "  !rm /content/gdrive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion/trashfile.f\n",
        "  time.sleep(2)\n",
        "  clear_output()\n",
        "  !gdown --fuzzy -O model.ckpt $Link_CKPT\n",
        "  if os.path.exists('/content/gdrive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion/model.ckpt'):\n",
        "    if os.path.getsize(\"/content/gdrive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion/model.ckpt\") > 1810671599:\n",
        "      model='/content/gdrive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion/model.ckpt'\n",
        "      clear_output()\n",
        "      print('\u001b[1;32mModel downloaded, using the trained model.')\n",
        "    else:\n",
        "      print('\u001b[1;31mWrong link, check that the link is valid')\n",
        "  else:\n",
        "    print('\u001b[1;31mWrong link, check that the link is valid')\n",
        "\n",
        "\n",
        "elif Model_Version==\"1.5\":\n",
        "  newmdl(token)\n",
        "\n",
        "elif Model_Version==\"V2.1-512px\" or Model_Version==\"V2.1-768px\":\n",
        "  V2(token)\n",
        "\n",
        "if RunwayML_Inpainting_Model:\n",
        "  inpmdl(token)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "xKEzM8k2mU-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Start WebUI\n",
        "You will now start the WebUI. First Time Start can take up to 4 Minutes."
      ],
      "metadata": {
        "id": "gAJa7kTgo5i_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from IPython.utils import capture\n",
        "import time\n",
        "import sys\n",
        "import fileinput\n",
        "import os\n",
        "from subprocess import getoutput\n",
        "#@markdown <font color='green'>**WebUI STEP 3:**</font> Start WebUI\n",
        "#@markdown \n",
        "#@markdown  Important! Select the correct version of the model.\n",
        "Model_Version = \"1.5\" #@param [\"1.5\", \"V2.1-512\", \"V2.1-768\"]\n",
        "\n",
        "\n",
        "Use_Gradio_Server = False\n",
        "\n",
        "Enable_API = False\n",
        "  \n",
        "with capture.capture_output() as cap: \n",
        "  if not os.path.exists('/tools/node/bin/lt'):\n",
        "    !npm install -g localtunnel\n",
        "\n",
        "with capture.capture_output() as cap: \n",
        "  %cd /content/gdrive/MyDrive/sd/stable-diffusion-webui/\n",
        "  time.sleep(1)\n",
        "  !wget -O webui.py https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/webui.py\n",
        "  !sed -i 's@ui.create_ui().*@ui.create_ui();shared.demo.queue(concurrency_count=10)@' /content/gdrive/MyDrive/sd/stable-diffusion-webui/webui.py\n",
        "  %cd /content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/\n",
        "  !wget -O ui.py https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/modules/ui.py\n",
        "  !sed -i 's@css = \"\".*@with open(os.path.join(script_path, \"style.css\"), \"r\", encoding=\"utf8\") as file:\\n        css = file.read()@' /content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/ui.py\n",
        "  %cd /content/gdrive/MyDrive/sd/stable-diffusion-webui\n",
        "  !wget -O style.css https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/style.css\n",
        "  !sed -i 's@min-height: 4.*@min-height: 5.5em;@g' /content/gdrive/MyDrive/sd/stable-diffusion-webui/style.css\n",
        "  !sed -i \"s@'extensions/depthmap2mask/scripts/depthmap_for_depth2img.py'@\\\"/content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/depthmap2mask/scripts/depthmap_for_depth2img.py\\\"@\" /content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/depthmap2mask/scripts/depth2image_depthmask.py\n",
        "  !sed -i 's@\"repositories/BoostingMonocularDepth\"@\\\"/content/gdrive/MyDrive/sd/stablediffusion/repositories/BoostingMonocularDepth\\\"@' /content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/stable-diffusion-webui-depthmap-script/scripts/depthmap.py\n",
        "  !sed -i 's@\"multiple_tqdm\": true,@\\\"multiple_tqdm\": false,@' /content/gdrive/MyDrive/sd/stable-diffusion-webui/config.json  \n",
        "  %cd /content\n",
        "\n",
        "\n",
        "share=''\n",
        "if Use_Gradio_Server:\n",
        "  share='--share'\n",
        "  for line in fileinput.input('/usr/local/lib/python3.8/dist-packages/gradio/blocks.py', inplace=True):\n",
        "    if line.strip().startswith('self.server_name ='):\n",
        "        line = '            self.server_name = server_name\\n'\n",
        "    if line.strip().startswith('self.server_port ='):\n",
        "        line = '            self.server_port = server_port\\n'\n",
        "    sys.stdout.write(line)\n",
        "  clear_output()\n",
        "  \n",
        "else:\n",
        "  share=''\n",
        "  !nohup lt --port 7860 > srv.txt 2>&1 &\n",
        "  time.sleep(2)\n",
        "  !grep -o 'https[^ ]*' /content/srv.txt >srvr.txt\n",
        "  time.sleep(2)\n",
        "  srv= getoutput('cat /content/srvr.txt')\n",
        "\n",
        "  for line in fileinput.input('/usr/local/lib/python3.8/dist-packages/gradio/blocks.py', inplace=True):\n",
        "    if line.strip().startswith('self.server_name ='):\n",
        "        line = f'            self.server_name = \"{srv[8:]}\"\\n'\n",
        "    if line.strip().startswith('self.server_port ='):\n",
        "        line = '            self.server_port = 443\\n'\n",
        "    if line.strip().startswith('self.protocol = \"https\"'):\n",
        "        line = '            self.protocol = \"https\"\\n'\n",
        "    if line.strip().startswith('if self.local_url.startswith(\"https\") or self.is_colab'):\n",
        "        line = ''    \n",
        "    if line.strip().startswith('else \"http\"'):\n",
        "        line = ''              \n",
        "    sys.stdout.write(line)\n",
        "          \n",
        "  !sed -i '13s@.*@    \"PUBLIC_SHARE_TRUE\": \"\u001b[32mConnected\",@' /usr/local/lib/python3.8/dist-packages/gradio/strings.py\n",
        "  \n",
        "  !rm /content/srv.txt\n",
        "  !rm /content/srvr.txt\n",
        "\n",
        "with capture.capture_output() as cap: \n",
        "  %cd /content/gdrive/MyDrive/sd/stablediffusion\n",
        "\n",
        "api = '--api' if Enable_API else ''\n",
        "\n",
        "if Model_Version == \"V2.1-768\":\n",
        "  configf=\"--config /content/gdrive/MyDrive/sd/stablediffusion/configs/stable-diffusion/v2-inference-v.yaml\"\n",
        "  !sed -i 's@def load_state_dict(checkpoint_path: str, map_location.*@def load_state_dict(checkpoint_path: str, map_location=\"cuda\"):@' /usr/local/lib/python3.8/dist-packages/open_clip/factory.py  \n",
        "elif Model_Version == \"V2.1-512\":\n",
        "  configf=\"--config /content/gdrive/MyDrive/sd/stablediffusion/configs/stable-diffusion/v2-inference.yaml\"\n",
        "  !sed -i 's@def load_state_dict(checkpoint_path: str, map_location.*@def load_state_dict(checkpoint_path: str, map_location=\"cuda\"):@' /usr/local/lib/python3.8/dist-packages/open_clip/factory.py  \n",
        "else:\n",
        "  configf=\"\"\n",
        "  !sed -i 's@def load_state_dict(checkpoint_path: str, map_location.*@def load_state_dict(checkpoint_path: str, map_location=\"cpu\"):@' /usr/local/lib/python3.8/dist-packages/open_clip/factory.py  \n",
        "\n",
        "if os.path.exists('/usr/local/lib/python3.8/dist-packages/xformers'):\n",
        "  xformers=\"--xformers\" \n",
        "else:\n",
        "  xformers=\"\"\n",
        "\n",
        "try:\n",
        "  model\n",
        "  if os.path.isfile(model):\n",
        "    !python /content/gdrive/MyDrive/sd/stable-diffusion-webui/webui.py $share $api --disable-safe-unpickle --no-half-vae  --ckpt \"$model\" $configf $xformers\n",
        "  else:\n",
        "    !python /content/gdrive/MyDrive/sd/stable-diffusion-webui/webui.py $share $api --disable-safe-unpickle --no-half-vae  --ckpt-dir \"$model\" $configf $xformers\n",
        "except:\n",
        "   !python /content/gdrive/MyDrive/sd/stable-diffusion-webui/webui.py $share $api --disable-safe-unpickle --no-half-vae $configf $xformers"
      ],
      "metadata": {
        "cellView": "form",
        "id": "RsOhmCCxpG4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Option 2:** Train a new Model\n",
        "Training a new model requires 5-20 Initital images. \n",
        "These should be images of the same object or person, however they must be all different!\n",
        "E.g. the person should wear different clothes and should have different poses and viewing angles. Also make sure that the background changes. Don't use to similar images."
      ],
      "metadata": {
        "id": "kvSwsB-2qFdH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Training Requirements\n",
        "\n",
        "The following will install all necessary requirements. Just click on the arrow on the left to start. (Takes about 1min)"
      ],
      "metadata": {
        "id": "xTlAZOcpsHu-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown <font color='purple'>**Training STEP 1:**</font> Install Requirements\n",
        "\n",
        "# Install Dreambooth requirements\n",
        "!wget -q https://github.com/ShivamShrirao/diffusers/raw/main/examples/dreambooth/train_dreambooth.py\n",
        "!wget -q https://github.com/ShivamShrirao/diffusers/raw/main/scripts/convert_diffusers_to_original_stable_diffusion.py\n",
        "%pip install -qq git+https://github.com/ShivamShrirao/diffusers\n",
        "%pip install -q -U --pre triton\n",
        "%pip install -q accelerate==0.12.0 transformers ftfy bitsandbytes gradio natsort\n",
        "\n",
        "# Install xformers\n",
        "%pip install -q https://github.com/brian6091/xformers-wheels/releases/download/0.0.15.dev0%2B4c06c79/xformers-0.0.15.dev0+4c06c79.d20221205-cp38-cp38-linux_x86_64.whl\n",
        "# These were compiled on Tesla T4.\n",
        "\n",
        "# If precompiled wheels don't work, install it with the following command. It will take around 40 minutes to compile.\n",
        "# %pip install git+https://github.com/facebookresearch/xformers@4c06c79#egg=xformers"
      ],
      "metadata": {
        "cellView": "form",
        "id": "pHaCjxM5jaG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save Model to Google Drive\n",
        "You can skip this part if you do not want to save your model to Google Drive.\n",
        "\n",
        "IMPORTANT: The model will be lost after you close the runtime or the browser window. \n",
        "\n"
      ],
      "metadata": {
        "id": "huspYWyZkNBe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown <font color=\"purple\">**Training STEP 2:**</font> Save model to Google Drive\n",
        "\n",
        "#@markdown If model weights should be saved directly in google drive (takes around 4-5 GB).  \n",
        "save_to_gdrive = True #@param {type:\"boolean\"}\n",
        "if save_to_gdrive:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "#@markdown Enter the directory name to save model at. I recommend to choose a folder name which is the same as your instance prompt\n",
        "\n",
        "OUTPUT_DIR = \"sd/dreambooth/stable_diffusion_weights/kasmedium\" #@param {type:\"string\"}\n",
        "if save_to_gdrive:\n",
        "    OUTPUT_DIR = \"/content/drive/MyDrive/\" + OUTPUT_DIR\n",
        "else:\n",
        "    OUTPUT_DIR = \"/content/\" + OUTPUT_DIR\n",
        "\n",
        "print(f\"[*] Weights will be saved at {OUTPUT_DIR}\")\n",
        "\n",
        "!mkdir -p $OUTPUT_DIR"
      ],
      "metadata": {
        "cellView": "form",
        "id": "sJKcyQIWl1HN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup Training Parameter"
      ],
      "metadata": {
        "id": "v0BP2R9yqxSy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown <font color=\"purple\">**Training STEP 3:**</font> Setup Parameter\n",
        "#@markdown ### Model Selection\n",
        "#@markdown\n",
        "#@markdown You do not need to change the base model if not required. If you want you can select a different model.\n",
        "Base_Model_Name = \"runwayml/stable-diffusion-v1-5\" #@param {type:\"string\"}\n",
        "\n",
        "MODEL_NAME = Base_Model_Name\n",
        "\n",
        "#@markdown\n",
        "#@markdown ### Model Parameter\n",
        "#@markdown \n",
        "#@markdown **Instance Prompt**\n",
        "#@markdown </br> The Instance prompt is your word which you will use to tell the AI that you want to have a picture of this person or object. The word should be unique. \n",
        "#@markdown </br> E.g. a normal prompt to the AI would be \"A Photo of a Cat\". If you want to train the AI on your cat, you could use the instance prompt \"kascat\". Then the new prompt would be \"A Photo of a kascat\". \n",
        "Instance_Prompt = \"kasmedium\" #@param {type:\"string\"}\n",
        "#@markdown **Class Prompt**\n",
        "#@markdown </br>If possible we should give the AI also a class which is the category our new prompt belongs too. In our example it would be \"cat\".\n",
        "Class_Prompt = \"man\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown While training the AI will need a directory. \n",
        "Instance_Data_Directory = \"/content/data/kasmedium\" #@param {type:\"string\"}\n",
        "Class_Data_Directory = \"/content/data/manmediuma\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "\n",
        "# You can also add multiple concepts here. Try tweaking `--max_train_steps` accordingly.\n",
        "\n",
        "concepts_list = [\n",
        "    {\n",
        "        \"instance_prompt\":      Instance_Prompt,\n",
        "        \"class_prompt\":         Class_Prompt,\n",
        "        \"instance_data_dir\":    Instance_Data_Directory,\n",
        "        \"class_data_dir\":       Class_Data_Directory\n",
        "    },\n",
        "#     {\n",
        "#         \"instance_prompt\":      \"photo of ukj person\",\n",
        "#         \"class_prompt\":         \"photo of a person\",\n",
        "#         \"instance_data_dir\":    \"/content/data/ukj\",\n",
        "#         \"class_data_dir\":       \"/content/data/person\"\n",
        "#     }\n",
        "]\n",
        "\n",
        "# `class_data_dir` contains regularization images\n",
        "import json\n",
        "import os\n",
        "for c in concepts_list:\n",
        "    os.makedirs(c[\"instance_data_dir\"], exist_ok=True)\n",
        "\n",
        "with open(\"concepts_list.json\", \"w\") as f:\n",
        "    json.dump(concepts_list, f, indent=4)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "nQCogg6_rUfn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Upload Images\n",
        "\n",
        "Your Pictures will be uploaded to Instance_Data_Directory. If this directory is local (e.g. /content/data/...) then every data uploaded there will be deleted after you close the runtime. I recommend this as you will just upload a few images and you can always reupload them. You can also upload your images to your Google Drive if you want to use them again.\n",
        "<font color=\"red\">It is recommend to do not upload more then **20** images</font> \n"
      ],
      "metadata": {
        "id": "PI4T2uDdypk6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown <font color=\"purple\">**Training STEP 4:**</font> Upload Images\n",
        "#@markdown </br> Just run this cell and you will be asked to upload the images.\n",
        "\n",
        "import os\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "for c in concepts_list:\n",
        "    print(f\"Uploading instance images for `{c['instance_prompt']}`\")\n",
        "    uploaded = files.upload()\n",
        "    for filename in uploaded.keys():\n",
        "        dst_path = os.path.join(c['instance_data_dir'], filename)\n",
        "        shutil.move(filename, dst_path)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Zz4j8CBB0Ron"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the Model\n",
        "\n",
        "You will now start the training with predefined values. If you know what you are doing you see and change the values in the code. \n",
        "This will take some time. Depending on the number of images between 10 to 40 minutes.\n",
        "\n",
        "Afterwards the code will produce 4 Output Images. These images are now a creation of the AI. Most of the images (not all of them) should look similar to your input images (at least in regards to your main object or person). It is possible that they are not similar. If this is the case run the \"Test your model\" below to check if the model still works. If not change the pictures and try again."
      ],
      "metadata": {
        "id": "TuiEpf9q1ENv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown <font color=\"purple\">**Training STEP 5:**</font> Run the Training\n",
        "\n",
        "# Count the number of images to get a rough idea of the training steps required.\n",
        "# A rule of thumb is 100 steps per image.\n",
        "import os\n",
        "\n",
        "# folder path\n",
        "dir_path = Instance_Data_Directory\n",
        "number_of_files = 0\n",
        "# Iterate directory\n",
        "for path in os.listdir(dir_path):\n",
        "    # check if current path is a file\n",
        "    if os.path.isfile(os.path.join(dir_path, path)):\n",
        "        number_of_files += 1\n",
        "\n",
        "MAX_TRAINING_STEPS = int(number_of_files*100)\n",
        "\n",
        "# Launch the Training\n",
        "\n",
        "!accelerate launch train_dreambooth.py \\\n",
        "  --pretrained_model_name_or_path=$MODEL_NAME \\\n",
        "  --pretrained_vae_name_or_path=\"stabilityai/sd-vae-ft-mse\" \\\n",
        "  --output_dir=$OUTPUT_DIR \\\n",
        "  --revision=\"fp16\" \\\n",
        "  --with_prior_preservation --prior_loss_weight=1.0 \\\n",
        "  --seed=1337 \\\n",
        "  --resolution=512 \\\n",
        "  --train_batch_size=1 \\\n",
        "  --train_text_encoder \\\n",
        "  --mixed_precision=\"fp16\" \\\n",
        "  --use_8bit_adam \\\n",
        "  --gradient_accumulation_steps=1 \\\n",
        "  --learning_rate=1e-6 \\\n",
        "  --lr_scheduler=\"constant\" \\\n",
        "  --lr_warmup_steps=0 \\\n",
        "  --num_class_images=50 \\\n",
        "  --sample_batch_size=4 \\\n",
        "  --max_train_steps=$MAX_TRAINING_STEPS \\\n",
        "  --save_interval=30000 \\\n",
        "  --save_sample_prompt=Instance_Prompt \\\n",
        "  --concepts_list=\"concepts_list.json\"\n",
        "\n",
        "# Reduce the `--save_interval` to lower than `--max_train_steps` to save weights from intermediate steps.\n",
        "# `--save_sample_prompt` can be same as `--instance_prompt` to generate intermediate samples (saved along with weights in samples directory).\n",
        "\n",
        "# Run to generate a grid of preview images from the last saved weights.\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "weights_folder = OUTPUT_DIR\n",
        "folders = sorted([f for f in os.listdir(weights_folder) if f != \"0\"], key=lambda x: int(x))\n",
        "\n",
        "row = len(folders)\n",
        "col = len(os.listdir(os.path.join(weights_folder, folders[0], \"samples\")))\n",
        "scale = 4\n",
        "fig, axes = plt.subplots(row, col, figsize=(col*scale, row*scale), gridspec_kw={'hspace': 0, 'wspace': 0})\n",
        "\n",
        "for i, folder in enumerate(folders):\n",
        "    folder_path = os.path.join(weights_folder, folder)\n",
        "    image_folder = os.path.join(folder_path, \"samples\")\n",
        "    images = [f for f in os.listdir(image_folder)]\n",
        "    for j, image in enumerate(images):\n",
        "        if row == 1:\n",
        "            currAxes = axes[j]\n",
        "        else:\n",
        "            currAxes = axes[i, j]\n",
        "        if i == 0:\n",
        "            currAxes.set_title(f\"Image {j}\")\n",
        "        if j == 0:\n",
        "            currAxes.text(-0.1, 0.5, folder, rotation=0, va='center', ha='center', transform=currAxes.transAxes)\n",
        "        image_path = os.path.join(image_folder, image)\n",
        "        img = mpimg.imread(image_path)\n",
        "        currAxes.imshow(img, cmap='gray')\n",
        "        currAxes.axis('off')\n",
        "        \n",
        "plt.tight_layout()\n",
        "plt.savefig('grid.png', dpi=72)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "bIWqBDsZ1Tv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create packaged Model\n",
        "If you want to use this model in your WebUI you need to package it into one .ckpt file (also known as checkpoint file). \n",
        "Info: the code will create an fp16 file which reduces the file to 2GB. You can change it to false if you know what you are doing. "
      ],
      "metadata": {
        "id": "qJ2Lxvk477Vv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown <font color=\"purple\">**Training STEP 6:**</font> Define Setting\n",
        "#@markdown\n",
        "#@markdown **Model Name**\n",
        "#@markdown </br> Provide a name of the model. E.g. you can use a word of your prompt like \"kascat\"\n",
        "model_name = \"/kasmedium/\" #@param {type: \"string\"}\n",
        "\n",
        "#This code allow the change of the Weights directory. As I want to keep it simple I will just assume that the weights directoy is the latest output directory\n",
        "WEIGHTS_DIR = \"\"\n",
        "if WEIGHTS_DIR == \"\":\n",
        "    from natsort import natsorted\n",
        "    from glob import glob\n",
        "    import os\n",
        "    WEIGHTS_DIR = natsorted(glob(OUTPUT_DIR + os.sep + \"*\"))[-1]\n",
        "print(f\"[*] WEIGHTS_DIR={WEIGHTS_DIR}\")\n",
        "\n",
        "ckpt_path = WEIGHTS_DIR + model_name+ \".ckpt\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "QFY_PQjbphPI",
        "outputId": "6b363350-bcd5-49fc-912d-d937a7c5ede6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*] WEIGHTS_DIR=/content/drive/MyDrive/sd/dreambooth/stable_diffusion_weights/kasmedium/1700\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown <font color=\"purple\">**Training STEP 7:**</font> Package Model\n",
        "#Run conversion.\n",
        "half_arg = \"\"\n",
        "\n",
        "#Whether to convert to fp16, takes half the space (2GB).\n",
        "fp16 = True\n",
        "if fp16:\n",
        "    half_arg = \"--half\"\n",
        "!python convert_diffusers_to_original_stable_diffusion.py --model_path $WEIGHTS_DIR  --checkpoint_path $ckpt_path $half_arg\n",
        "print(f\"[*] Path to your Model: {ckpt_path}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ybo49b8R7Wkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test your Model\n",
        "You can now use your model by starting the WebUI and adding the \"Path to your Model\" shown above into the Path_to_CKPT variable in the WebUI section. \n",
        "However to run some quick tests you can just run the blow code.\n"
      ],
      "metadata": {
        "id": "2W4GFxlm-fkP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown <font color=\"purple\">**Training STEP 8:**</font> Test your Model\n",
        "# Setup the Pipeline\n",
        "import torch\n",
        "from torch import autocast\n",
        "from diffusers import StableDiffusionPipeline, DDIMScheduler\n",
        "from IPython.display import display\n",
        "\n",
        "model_path = WEIGHTS_DIR             # If you want to use previously trained model saved in gdrive, replace this with the full path of model in gdrive\n",
        "\n",
        "scheduler = DDIMScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", clip_sample=False, set_alpha_to_one=False)\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_path, scheduler=scheduler, safety_checker=None, torch_dtype=torch.float16).to(\"cuda\")\n",
        "\n",
        "g_cuda = None\n",
        "\n",
        "#@markdown **Prompt**\n",
        "#@markdown </br> Change it to what you want to get created. Use your instance_prompt\n",
        "prompt = \"kasmedium with cyberpunk clothing, with nice landscape in the background, change clothing to cyberpunk\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown **Basic Input Parameters**\n",
        "#@markdown </br> You do not need to change them if you don't want and you can keep the negative prompt empty.\n",
        "g_cuda = torch.Generator(device='cuda')\n",
        "seed = -1 #@param {type:\"number\"}\n",
        "g_cuda.manual_seed(seed)\n",
        "\n",
        "\n",
        "#Run for generating images.\n",
        "\n",
        "negative_prompt = \"\" #@param {type:\"string\"}\n",
        "num_samples = 1 #@param {type:\"number\"}\n",
        "guidance_scale = 7.5 #@param {type:\"number\"}\n",
        "num_inference_steps = 50 #@param {type:\"number\"}\n",
        "height = 512 #@param {type:\"number\"}\n",
        "width = 512 #@param {type:\"number\"}\n",
        "\n",
        "with autocast(\"cuda\"), torch.inference_mode():\n",
        "    images = pipe(\n",
        "        prompt,\n",
        "        height=height,\n",
        "        width=width,\n",
        "        negative_prompt=negative_prompt,\n",
        "        num_images_per_prompt=num_samples,\n",
        "        num_inference_steps=num_inference_steps,\n",
        "        guidance_scale=guidance_scale,\n",
        "        generator=g_cuda\n",
        "    ).images\n",
        "\n",
        "for img in images:\n",
        "    display(img)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "OKADiAan_mhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (Optional) Free up runtime memory\n",
        "In case of the following Error: **OutOfMemoryError: CUDA out of memory.**\n",
        "\n",
        "Sometimes the memory runs full. In this case just execute the below code to restart the runtime.\n",
        "\n",
        "If you do this you need to run Step 2 and 6 **again** before you can run Step 7."
      ],
      "metadata": {
        "id": "Bgk4eZ6CB98T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown **Optional STEP 1:** Free Memory\n",
        "exit()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "6LVu-arACJSO"
      },
      "execution_count": 23,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}